#!/usr/bin/env python3
"""
æ‹¥æŒ¤åº¦ç›‘æ§ - è®¡ç®— & ç”ŸæˆJSON
1. ä¸‰è·¯èµ„é‡‘æ–¹å‘ä¸€è‡´æ€§ï¼ˆåŒ—å‘/ETF/ä¸¤èï¼‰
2. è¡Œä¸šèµ„é‡‘æµå‘çƒ­åŠ›å›¾
3. æ‹¥æŒ¤åº¦ç»¼åˆä¿¡å·
"""
import os, json
import pandas as pd
import numpy as np

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.join(SCRIPT_DIR, 'cache')
OUTPUT_JSON = os.path.join(SCRIPT_DIR, 'crowding.json')


def load_csv(name):
    path = os.path.join(CACHE_DIR, name)
    if not os.path.exists(path):
        return pd.DataFrame()
    df = pd.read_csv(path)
    if 'trade_date' in df.columns:
        df['trade_date'] = pd.to_datetime(df['trade_date'])
    return df


def calc_direction_signal(series, window=5):
    """è®¡ç®—èµ„é‡‘æ–¹å‘: MA5 > MA20 ä¸ºæ­£ï¼Œå¦åˆ™ä¸ºè´Ÿ"""
    ma5 = series.rolling(window).mean()
    ma20 = series.rolling(20).mean()
    return np.where(ma5 > ma20, 1, -1)


def calc_crowding():
    north = load_csv('northbound.csv')
    etf = load_csv('etf_flow.csv')
    margin = load_csv('margin.csv')
    industry = load_csv('industry_flow.csv')
    
    result = {
        'update_time': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'),
        'three_flows': {},
        'direction_chart': [],
        'industry_heatmap': [],
        'crowding_signal': {},
    }
    
    # â”€â”€ åˆå¹¶ä¸‰è·¯æ•°æ® â”€â”€
    # æ‰¾å…±åŒæ—¥æœŸèŒƒå›´
    dfs = []
    if not north.empty:
        dfs.append(north.set_index('trade_date')[['north_net']])
    if not etf.empty:
        dfs.append(etf.set_index('trade_date')[['etf_share_chg']])
    if not margin.empty:
        dfs.append(margin.set_index('trade_date')[['margin_chg', 'margin_balance']])
    
    if not dfs:
        print("æ— æ•°æ®å¯è®¡ç®—!")
        with open(OUTPUT_JSON, 'w') as f:
            json.dump(result, f, ensure_ascii=False)
        return
    
    merged = pd.concat(dfs, axis=1).sort_index()
    merged = merged.dropna(subset=[c for c in ['north_net'] if c in merged.columns])
    
    # æœ€è¿‘60å¤©ç”¨äºå›¾è¡¨
    recent = merged.tail(60).copy()
    
    # â”€â”€ ä¸‰è·¯æ–¹å‘ä¸€è‡´æ€§ â”€â”€
    directions = {}
    labels = {'north_net': 'åŒ—å‘èµ„é‡‘', 'etf_share_chg': 'ETFå‡€æµå…¥', 'margin_chg': 'ä¸¤èå˜åŒ–'}
    
    for col, label in labels.items():
        if col not in recent.columns:
            continue
        s = recent[col].fillna(0)
        ma5 = s.rolling(5, min_periods=1).mean()
        ma20 = s.rolling(20, min_periods=5).mean()
        latest_dir = 'inflow' if ma5.iloc[-1] > ma20.iloc[-1] else 'outflow'
        directions[col] = {
            'name': label,
            'direction': latest_dir,
            'latest': round(float(s.iloc[-1]), 2),
            'ma5': round(float(ma5.iloc[-1]), 2),
            'ma20': round(float(ma20.iloc[-1]), 2),
        }
    
    # ä¸€è‡´æ€§åˆ¤æ–­
    dir_values = [v['direction'] for v in directions.values()]
    if len(set(dir_values)) == 1 and len(dir_values) >= 2:
        consensus = dir_values[0]
        consensus_label = 'ä¸‰è·¯å…±æŒ¯æµå…¥ ğŸŸ¢' if consensus == 'inflow' else 'ä¸‰è·¯å…±æŒ¯æµå‡º ğŸ”´'
    elif len(dir_values) >= 2:
        inflow_count = dir_values.count('inflow')
        if inflow_count >= 2:
            consensus_label = 'åå¤šåˆ†æ­§ ğŸŸ¡'
        else:
            consensus_label = 'åç©ºåˆ†æ­§ ğŸŸ¡'
    else:
        consensus_label = 'æ•°æ®ä¸è¶³'
    
    result['three_flows'] = {
        'details': directions,
        'consensus': consensus_label,
    }
    
    # â”€â”€ å›¾è¡¨æ•°æ®ï¼ˆ60å¤©æ—¶åºï¼‰â”€â”€
    chart_data = []
    for idx, row in recent.iterrows():
        d = {'date': idx.strftime('%m-%d')}
        for col in ['north_net', 'etf_share_chg', 'margin_chg']:
            if col in row:
                d[col] = round(float(row[col]), 2) if pd.notna(row[col]) else None
        chart_data.append(d)
    result['direction_chart'] = chart_data
    
    # â”€â”€ ç´¯è®¡å‡€æµå…¥ï¼ˆ20æ—¥æ»šåŠ¨ï¼‰â”€â”€
    rolling_data = []
    for col, label in labels.items():
        if col not in merged.columns:
            continue
        s = merged[col].fillna(0)
        cum20 = s.rolling(20, min_periods=1).sum()
        recent_cum = cum20.tail(60)
        series = []
        for idx, val in recent_cum.items():
            series.append({
                'date': idx.strftime('%m-%d'),
                'value': round(float(val), 2),
            })
        rolling_data.append({'name': label, 'key': col, 'data': series})
    result['rolling_cum'] = rolling_data
    
    # â”€â”€ è¡Œä¸šçƒ­åŠ›å›¾ï¼ˆæœ€è¿‘5æ—¥å‡€æµå…¥æ’åï¼‰â”€â”€
    if not industry.empty:
        industry['trade_date'] = pd.to_datetime(industry['trade_date'])
        # net_amount å•ä½ä¸‡å…ƒ -> äº¿
        if 'net_amount' in industry.columns:
            industry['net_amount'] = industry['net_amount'].astype(float)
            # æŒ‰è¡Œä¸šæ±‡æ€»æœ€è¿‘5æ—¥
            ind_sum = industry.groupby('name')['net_amount'].sum().reset_index()
            ind_sum.columns = ['industry', 'net_5d']
            # è½¬äº¿ï¼ˆå¦‚æœå•ä½æ˜¯ä¸‡å…ƒï¼‰
            if ind_sum['net_5d'].abs().max() > 1e6:
                ind_sum['net_5d'] = ind_sum['net_5d'] / 1e4
            elif ind_sum['net_5d'].abs().max() > 1e3:
                ind_sum['net_5d'] = ind_sum['net_5d'] / 1e4
            ind_sum = ind_sum.sort_values('net_5d', ascending=False)
            
            # æ¯æ—¥æ•°æ®ï¼ˆç”¨äºçƒ­åŠ›å›¾ï¼‰
            daily_ind = []
            for td in sorted(industry['trade_date'].unique()):
                day_data = industry[industry['trade_date'] == td]
                for _, row in day_data.iterrows():
                    val = float(row['net_amount'])
                    if abs(val) > 1e6:
                        val = val / 1e4
                    elif abs(val) > 1e3:
                        val = val / 1e4
                    daily_ind.append({
                        'date': pd.Timestamp(td).strftime('%m-%d'),
                        'industry': str(row['name']),
                        'net': round(val, 2),
                    })
            
            result['industry_heatmap'] = {
                'summary': [{'industry': r['industry'], 'net_5d': round(r['net_5d'], 2)} 
                           for _, r in ind_sum.iterrows()],
                'daily': daily_ind,
            }
    
    # â”€â”€ æ‹¥æŒ¤åº¦ç»¼åˆä¿¡å· â”€â”€
    signals = []
    
    # 1. ä¸‰è·¯å…±æŒ¯
    if 'å…±æŒ¯' in consensus_label:
        signals.append(consensus_label)
    
    # 2. åŒ—å‘æå€¼ï¼ˆ20æ—¥å†…æœ€å¤§/æœ€å°ï¼‰
    if 'north_net' in merged.columns:
        n20 = merged['north_net'].tail(20)
        latest_n = n20.iloc[-1] if len(n20) > 0 else 0
        pct = n20.rank(pct=True).iloc[-1] if len(n20) > 0 else 0.5
        if pct > 0.9:
            signals.append(f'åŒ—å‘å•æ—¥æç«¯æµå…¥({latest_n:.1f}äº¿) âš ï¸')
        elif pct < 0.1:
            signals.append(f'åŒ—å‘å•æ—¥æç«¯æµå‡º({latest_n:.1f}äº¿) âš ï¸')
    
    # 3. ä¸¤èä½™é¢é«˜ä½
    if 'margin_balance' in merged.columns:
        mb = merged['margin_balance'].dropna()
        if len(mb) > 60:
            pct60 = (mb.iloc[-1] - mb.tail(60).min()) / (mb.tail(60).max() - mb.tail(60).min() + 1e-9)
            if pct60 > 0.9:
                signals.append(f'ä¸¤èä½™é¢60æ—¥é«˜ä½({mb.iloc[-1]:.0f}äº¿) ğŸ”´')
            elif pct60 < 0.1:
                signals.append(f'ä¸¤èä½™é¢60æ—¥ä½ä½({mb.iloc[-1]:.0f}äº¿) ğŸŸ¢')
    
    result['crowding_signal'] = {
        'signals': signals if signals else ['å½“å‰æ— æç«¯ä¿¡å· âœ…'],
        'consensus': consensus_label,
    }
    
    # â”€â”€ ä¸¤èä½™é¢è¶‹åŠ¿ â”€â”€
    if 'margin_balance' in merged.columns:
        mb_recent = merged['margin_balance'].dropna().tail(60)
        result['margin_trend'] = [
            {'date': idx.strftime('%m-%d'), 'balance': round(float(val), 0)}
            for idx, val in mb_recent.items()
        ]
    
    # ä¿å­˜
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"è¾“å‡º: {OUTPUT_JSON}")
    print(f"ä¿¡å·: {consensus_label}")
    if signals:
        for s in signals:
            print(f"  - {s}")


if __name__ == '__main__':
    calc_crowding()
