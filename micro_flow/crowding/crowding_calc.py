#!/usr/bin/env python3
"""
æ‹¥æŒ¤åº¦ç›‘æ§ - è®¡ç®— & ç”ŸæˆJSON
1. ä¸‰è·¯èµ„é‡‘æ–¹å‘ä¸€è‡´æ€§ï¼ˆåŒ—å‘/ETF/ä¸¤èï¼‰
2. è¡Œä¸šèµ„é‡‘æµå‘çƒ­åŠ›å›¾
3. æ‹¥æŒ¤åº¦ç»¼åˆä¿¡å·
"""
import os, json
import pandas as pd
import numpy as np

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.join(SCRIPT_DIR, 'cache')
OUTPUT_JSON = os.path.join(SCRIPT_DIR, 'crowding.json')


def load_csv(name):
    path = os.path.join(CACHE_DIR, name)
    if not os.path.exists(path):
        return pd.DataFrame()
    df = pd.read_csv(path)
    if 'trade_date' in df.columns:
        df['trade_date'] = pd.to_datetime(df['trade_date'])
    return df


def calc_direction_signal(series, window=5):
    """è®¡ç®—èµ„é‡‘æ–¹å‘: MA5 > MA20 ä¸ºæ­£ï¼Œå¦åˆ™ä¸ºè´Ÿ"""
    ma5 = series.rolling(window).mean()
    ma20 = series.rolling(20).mean()
    return np.where(ma5 > ma20, 1, -1)


def calc_crowding():
    north = load_csv('northbound.csv')
    etf = load_csv('etf_flow.csv')
    margin = load_csv('margin.csv')
    industry = load_csv('industry_flow.csv')
    
    result = {
        'update_time': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'),
        'three_flows': {},
        'direction_chart': [],
        'industry_heatmap': [],
        'crowding_signal': {},
    }
    
    # â”€â”€ åˆå¹¶ä¸‰è·¯æ•°æ® â”€â”€
    # æ‰¾å…±åŒæ—¥æœŸèŒƒå›´
    dfs = []
    if not north.empty:
        dfs.append(north.set_index('trade_date')[['north_net']])
    if not etf.empty:
        dfs.append(etf.set_index('trade_date')[['etf_share_chg']])
    if not margin.empty:
        dfs.append(margin.set_index('trade_date')[['margin_chg', 'margin_balance']])
    
    if not dfs:
        print("æ— æ•°æ®å¯è®¡ç®—!")
        with open(OUTPUT_JSON, 'w') as f:
            json.dump(result, f, ensure_ascii=False)
        return
    
    merged = pd.concat(dfs, axis=1).sort_index()
    merged = merged.dropna(subset=[c for c in ['north_net'] if c in merged.columns])
    
    # æœ€è¿‘60å¤©ç”¨äºå›¾è¡¨
    recent = merged.tail(60).copy()
    
    # â”€â”€ ä¸‰è·¯æ–¹å‘ä¸€è‡´æ€§ â”€â”€
    directions = {}
    labels = {'north_net': 'åŒ—å‘èµ„é‡‘', 'etf_share_chg': 'ETFå‡€æµå…¥', 'margin_chg': 'ä¸¤èå˜åŒ–'}
    
    for col, label in labels.items():
        if col not in recent.columns:
            continue
        s = recent[col].fillna(0)
        ma5 = s.rolling(5, min_periods=1).mean()
        ma20 = s.rolling(20, min_periods=5).mean()
        latest_dir = 'inflow' if ma5.iloc[-1] > ma20.iloc[-1] else 'outflow'
        directions[col] = {
            'name': label,
            'direction': latest_dir,
            'latest': round(float(s.iloc[-1]), 2),
            'ma5': round(float(ma5.iloc[-1]), 2),
            'ma20': round(float(ma20.iloc[-1]), 2),
        }
    
    # ä¸€è‡´æ€§åˆ¤æ–­
    dir_values = [v['direction'] for v in directions.values()]
    if len(set(dir_values)) == 1 and len(dir_values) >= 2:
        consensus = dir_values[0]
        consensus_label = 'ä¸‰è·¯å…±æŒ¯æµå…¥ ğŸŸ¢' if consensus == 'inflow' else 'ä¸‰è·¯å…±æŒ¯æµå‡º ğŸ”´'
    elif len(dir_values) >= 2:
        inflow_count = dir_values.count('inflow')
        if inflow_count >= 2:
            consensus_label = 'åå¤šåˆ†æ­§ ğŸŸ¡'
        else:
            consensus_label = 'åç©ºåˆ†æ­§ ğŸŸ¡'
    else:
        consensus_label = 'æ•°æ®ä¸è¶³'
    
    result['three_flows'] = {
        'details': directions,
        'consensus': consensus_label,
    }
    
    # â”€â”€ å›¾è¡¨æ•°æ®ï¼ˆ60å¤©æ—¶åºï¼‰â”€â”€
    chart_data = []
    for idx, row in recent.iterrows():
        d = {'date': idx.strftime('%m-%d')}
        for col in ['north_net', 'etf_share_chg', 'margin_chg']:
            if col in row:
                d[col] = round(float(row[col]), 2) if pd.notna(row[col]) else None
        chart_data.append(d)
    result['direction_chart'] = chart_data
    
    # â”€â”€ ç´¯è®¡å‡€æµå…¥ï¼ˆ20æ—¥æ»šåŠ¨ï¼‰â”€â”€
    rolling_data = []
    for col, label in labels.items():
        if col not in merged.columns:
            continue
        s = merged[col].fillna(0)
        cum20 = s.rolling(20, min_periods=1).sum()
        recent_cum = cum20.tail(60)
        series = []
        for idx, val in recent_cum.items():
            series.append({
                'date': idx.strftime('%m-%d'),
                'value': round(float(val), 2),
            })
        rolling_data.append({'name': label, 'key': col, 'data': series})
    result['rolling_cum'] = rolling_data
    
    # â”€â”€ è¡Œä¸šçƒ­åŠ›å›¾ï¼ˆç”³ä¸‡ä¸€çº§ï¼Œè¿‘5æ—¥æ¶¨è·Œå¹…+æˆäº¤é¢ï¼‰â”€â”€
    if not industry.empty:
        industry['trade_date'] = pd.to_datetime(industry['trade_date'])
        industry['pct_change'] = pd.to_numeric(industry['pct_change'], errors='coerce')
        industry['amount'] = pd.to_numeric(industry['amount'], errors='coerce')
        
        # æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥
        dates_sorted = sorted(industry['trade_date'].unique())
        last5 = dates_sorted[-5:] if len(dates_sorted) >= 5 else dates_sorted
        ind5 = industry[industry['trade_date'].isin(last5)]
        
        # 5æ—¥ç´¯è®¡æ¶¨è·Œå¹…ï¼ˆå¤åˆ©ï¼‰
        ind_cum = []
        for name, grp in ind5.groupby('name'):
            grp = grp.sort_values('trade_date')
            cum_ret = ((1 + grp['pct_change'] / 100).prod() - 1) * 100
            avg_amount = grp['amount'].mean()
            ind_cum.append({
                'industry': name,
                'pct_5d': round(cum_ret, 2),
                'avg_amount': round(avg_amount, 0),
            })
        ind_cum = sorted(ind_cum, key=lambda x: x['pct_5d'], reverse=True)
        
        # æ¯æ—¥æ•°æ®
        daily_ind = []
        for td in sorted(industry['trade_date'].unique()):
            day_data = industry[industry['trade_date'] == td]
            for _, row in day_data.iterrows():
                daily_ind.append({
                    'date': pd.Timestamp(td).strftime('%m-%d'),
                    'industry': str(row['name']),
                    'pct': round(float(row['pct_change']), 2) if pd.notna(row['pct_change']) else 0,
                })
        
        result['industry_heatmap'] = {
            'summary': ind_cum,
            'daily': daily_ind,
        }
    
    # â”€â”€ æ‹¥æŒ¤åº¦ç»¼åˆä¿¡å· â”€â”€
    signals = []
    
    # 1. ä¸‰è·¯å…±æŒ¯
    if 'å…±æŒ¯' in consensus_label:
        signals.append(consensus_label)
    
    # 2. åŒ—å‘æå€¼ï¼ˆ20æ—¥å†…æœ€å¤§/æœ€å°ï¼‰
    if 'north_net' in merged.columns:
        n20 = merged['north_net'].tail(20)
        latest_n = n20.iloc[-1] if len(n20) > 0 else 0
        pct = n20.rank(pct=True).iloc[-1] if len(n20) > 0 else 0.5
        if pct > 0.9:
            signals.append(f'åŒ—å‘å•æ—¥æç«¯æµå…¥({latest_n:.1f}äº¿) âš ï¸')
        elif pct < 0.1:
            signals.append(f'åŒ—å‘å•æ—¥æç«¯æµå‡º({latest_n:.1f}äº¿) âš ï¸')
    
    # 3. ä¸¤èä½™é¢é«˜ä½
    if 'margin_balance' in merged.columns:
        mb = merged['margin_balance'].dropna()
        if len(mb) > 60:
            pct60 = (mb.iloc[-1] - mb.tail(60).min()) / (mb.tail(60).max() - mb.tail(60).min() + 1e-9)
            if pct60 > 0.9:
                signals.append(f'ä¸¤èä½™é¢60æ—¥é«˜ä½({mb.iloc[-1]:.0f}äº¿) ğŸ”´')
            elif pct60 < 0.1:
                signals.append(f'ä¸¤èä½™é¢60æ—¥ä½ä½({mb.iloc[-1]:.0f}äº¿) ğŸŸ¢')
    
    result['crowding_signal'] = {
        'signals': signals if signals else ['å½“å‰æ— æç«¯ä¿¡å· âœ…'],
        'consensus': consensus_label,
    }
    
    # â”€â”€ ä¸¤èä½™é¢è¶‹åŠ¿ â”€â”€
    if 'margin_balance' in merged.columns:
        mb_recent = merged['margin_balance'].dropna().tail(60)
        result['margin_trend'] = [
            {'date': idx.strftime('%m-%d'), 'balance': round(float(val), 0)}
            for idx, val in mb_recent.items()
        ]
    
    # ä¿å­˜
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"è¾“å‡º: {OUTPUT_JSON}")
    print(f"ä¿¡å·: {consensus_label}")
    if signals:
        for s in signals:
            print(f"  - {s}")


if __name__ == '__main__':
    calc_crowding()
