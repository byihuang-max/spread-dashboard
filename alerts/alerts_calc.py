#!/usr/bin/env python3
"""
çº¢ç¯é¢„è­¦ - è®¡ç®—5ç»´é£é™© + ç»¼åˆè¯„åˆ†
å¤ç”¨: liquidity/rates/crowding/option_sentiment çš„cache/json
è‡ªæœ‰: valuation + limit_stats + market_amount
"""
import os, json
import pandas as pd
import numpy as np

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.join(SCRIPT_DIR, 'cache')
OUTPUT_JSON = os.path.join(SCRIPT_DIR, 'alerts.json')

BASE = os.path.dirname(SCRIPT_DIR)  # gamt-dashboard
LIQUIDITY_CACHE = os.path.join(BASE, 'macro', 'liquidity', 'cache')
RATES_JSON = os.path.join(BASE, 'macro', 'rates', 'rates.json')
CROWDING_JSON = os.path.join(BASE, 'micro_flow', 'crowding', 'crowding.json')
OPTION_JSON = os.path.join(BASE, 'micro_flow', 'option_sentiment', 'option_sentiment.json')


def load_csv(directory, name):
    path = os.path.join(directory, name)
    return pd.read_csv(path) if os.path.exists(path) else pd.DataFrame()


def load_json(path):
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def percentile_rank(series, value):
    """è®¡ç®—valueåœ¨seriesä¸­çš„åˆ†ä½æ•°(0-100)"""
    if len(series) == 0 or value is None:
        return None
    return round(float((series < value).sum() / len(series) * 100), 1)


def calc():
    result = {
        'update_time': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'),
        'dimensions': {},
        'composite_score': 0,
        'composite_level': '',
        'alerts': [],  # æ–‡å­—é¢„è­¦
    }

    scores = {}  # æ¯ç»´åº¦0-100 (100=æœ€å±é™©)

    # â•â•â•â•â•â•â• 1. æµåŠ¨æ€§é£é™© â•â•â•â•â•â•â•
    liq = {'name': 'ğŸ’§ æµåŠ¨æ€§é£é™©', 'level': 'ğŸŸ¢', 'score': 0, 'items': [], 'trend': []}

    dr_df = load_csv(LIQUIDITY_CACHE, 'dr007.csv')
    shibor_df = load_csv(LIQUIDITY_CACHE, 'shibor.csv')

    if not dr_df.empty:
        dr_df['close'] = pd.to_numeric(dr_df['close'], errors='coerce')
        dr_df = dr_df.dropna(subset=['close']).sort_values('trade_date')
        latest_dr = float(dr_df.iloc[-1]['close'])
        ma20 = float(dr_df['close'].tail(20).mean())
        deviation = (latest_dr - ma20) / ma20 * 100

        liq['items'].append(f"DR007: {latest_dr:.2f}% (MA20: {ma20:.2f}%)")
        liq['trend'] = [{'date': str(int(r['trade_date']))[4:8], 'value': round(float(r['close']), 3)}
                        for _, r in dr_df.iterrows()]

        # R-Dä»·å·®
        if 'r007_close' in dr_df.columns:
            dr_df['r007_close'] = pd.to_numeric(dr_df['r007_close'], errors='coerce')
            latest_r = dr_df.dropna(subset=['r007_close']).iloc[-1]['r007_close'] if dr_df['r007_close'].notna().any() else None
            if latest_r is not None:
                spread = float(latest_r) - latest_dr
                liq['items'].append(f"R007-DR007ä»·å·®: {spread*100:.0f}bp")
                if spread > 1.0:
                    liq['score'] += 30

        # è¯„åˆ†
        if latest_dr > 2.5:
            liq['score'] += 70
        elif latest_dr > 2.0:
            liq['score'] += 40
        elif deviation > 15:
            liq['score'] += 30

    if not shibor_df.empty:
        shibor_df['on'] = pd.to_numeric(shibor_df['on'], errors='coerce')
        latest_on = float(shibor_df.dropna(subset=['on']).iloc[-1]['on'])
        liq['items'].append(f"Shiboréš”å¤œ: {latest_on:.3f}%")
        if latest_on > 2.5:
            liq['score'] += 20

    liq['score'] = min(liq['score'], 100)
    scores['liquidity'] = liq['score']
    if liq['score'] >= 60:
        liq['level'] = 'ğŸ”´'
        result['alerts'].append('ğŸ’§ èµ„é‡‘é¢ç´§å¼ ï¼ŒDR007æ˜¾è‘—åé«˜')
    elif liq['score'] >= 30:
        liq['level'] = 'ğŸŸ¡'
    result['dimensions']['liquidity'] = liq

    # â•â•â•â•â•â•â• 2. ä¼°å€¼æ³¡æ²« â•â•â•â•â•â•â•
    val = {'name': 'ğŸ“Š ä¼°å€¼æ³¡æ²«', 'level': 'ğŸŸ¢', 'score': 0, 'items': [], 'trend': []}

    for code, name in [('000001', 'ä¸Šè¯'), ('000300', 'æ²ªæ·±300'), ('399006', 'åˆ›ä¸šæ¿')]:
        df = load_csv(CACHE_DIR, f'valuation_{code}.csv')
        if not df.empty:
            df['pe_ttm'] = pd.to_numeric(df['pe_ttm'], errors='coerce')
            df = df.dropna(subset=['pe_ttm']).sort_values('trade_date')
            latest_pe = float(df.iloc[-1]['pe_ttm'])
            pct = percentile_rank(df['pe_ttm'], latest_pe)
            val['items'].append(f"{name} PE(TTM): {latest_pe:.1f} (åˆ†ä½: {pct:.0f}%)")

            if code == '000001':
                val['trend'] = [{'date': str(int(r['trade_date']))[4:8], 'value': round(float(r['pe_ttm']), 1)}
                                for _, r in df.iterrows()]

            # è¯„åˆ†
            if pct is not None:
                if code == '000001':
                    if pct > 90: val['score'] += 40
                    elif pct > 75: val['score'] += 20
                elif code == '399006':
                    if pct > 90: val['score'] += 30
                    elif pct > 75: val['score'] += 15

    # è‚¡å€ºæ€§ä»·æ¯” (EP - 10Yå›½å€º)
    rates_data = load_json(RATES_JSON)
    cn10y_list = rates_data.get('cn10y', [])
    if cn10y_list:
        cn10y_val = cn10y_list[-1]['value']
        sh_df = load_csv(CACHE_DIR, 'valuation_000001.csv')
        if not sh_df.empty:
            sh_df['pe_ttm'] = pd.to_numeric(sh_df['pe_ttm'], errors='coerce')
            latest_pe = float(sh_df.dropna(subset=['pe_ttm']).iloc[-1]['pe_ttm'])
            ep = 100 / latest_pe  # ç›ˆåˆ©æ”¶ç›Šç‡
            equity_bond = round(ep - cn10y_val, 2)
            val['items'].append(f"è‚¡å€ºæ€§ä»·æ¯”(EP-10Y): {equity_bond:.2f}%")
            if equity_bond < 0:
                val['score'] += 30
                result['alerts'].append('ğŸ“Š è‚¡å€ºæ€§ä»·æ¯”ä¸ºè´Ÿï¼Œè‚¡ç¥¨ç›¸å¯¹å€ºåˆ¸æ— å¸å¼•åŠ›')
            elif equity_bond < 1:
                val['score'] += 15

    val['score'] = min(val['score'], 100)
    scores['valuation'] = val['score']
    if val['score'] >= 60:
        val['level'] = 'ğŸ”´'
        result['alerts'].append('ğŸ“Š å¸‚åœºä¼°å€¼å¤„äºå†å²é«˜ä½åŒºé—´')
    elif val['score'] >= 30:
        val['level'] = 'ğŸŸ¡'
    result['dimensions']['valuation'] = val

    # â•â•â•â•â•â•â• 3. æƒ…ç»ªè¿‡çƒ­ â•â•â•â•â•â•â•
    senti = {'name': 'ğŸ”¥ æƒ…ç»ªè¿‡çƒ­', 'level': 'ğŸŸ¢', 'score': 0, 'items': [], 'trend': []}

    # æˆäº¤é¢
    amt_df = load_csv(CACHE_DIR, 'market_amount.csv')
    if not amt_df.empty:
        amt_df['amount'] = pd.to_numeric(amt_df['amount'], errors='coerce')
        amt_df = amt_df.dropna(subset=['amount']).sort_values('trade_date')
        latest_amt = float(amt_df.iloc[-1]['amount'])
        ma20_amt = float(amt_df['amount'].tail(20).mean())
        ratio = latest_amt / ma20_amt if ma20_amt > 0 else 1
        senti['items'].append(f"ä¸Šè¯æˆäº¤é¢/MA20: {ratio:.2f}x")
        senti['trend'] = [{'date': str(int(r['trade_date']))[4:8], 'value': round(float(r['amount']) / 1e8, 1)}
                          for _, r in amt_df.iterrows()]

        if ratio > 1.8:
            senti['score'] += 40
        elif ratio > 1.5:
            senti['score'] += 20

    # æ¶¨è·Œåœ
    limit_df = load_csv(CACHE_DIR, 'limit_stats.csv')
    if not limit_df.empty:
        limit_df = limit_df.sort_values('trade_date')
        latest_up = int(limit_df.iloc[-1]['up_limit'])
        latest_down = int(limit_df.iloc[-1]['down_limit'])
        senti['items'].append(f"æ¶¨åœ: {latest_up}åª | è·Œåœ: {latest_down}åª")

        if latest_up > 80:
            senti['score'] += 25
        if latest_down > 50:
            senti['score'] += 20
            result['alerts'].append(f'ğŸ”¥ è·Œåœ{latest_down}åªï¼Œææ…Œæƒ…ç»ªè”“å»¶')

    # èèµ„ä¹°å…¥å æ¯”ï¼ˆå¤ç”¨crowdingï¼‰
    margin_df = load_csv(os.path.join(BASE, 'micro_flow', 'crowding', 'cache'), 'margin.csv')
    if not margin_df.empty:
        margin_df['rzye'] = pd.to_numeric(margin_df.get('rzye', pd.Series()), errors='coerce')
        if 'rzye' in margin_df.columns and margin_df['rzye'].notna().any():
            latest_rz = float(margin_df.sort_values('trade_date').iloc[-1]['rzye'])
            senti['items'].append(f"èèµ„ä½™é¢: {latest_rz/1e8:.0f}äº¿")

    senti['score'] = min(senti['score'], 100)
    scores['sentiment'] = senti['score']
    if senti['score'] >= 60:
        senti['level'] = 'ğŸ”´'
        result['alerts'].append('ğŸ”¥ å¸‚åœºæƒ…ç»ªè¿‡çƒ­ï¼Œæˆäº¤æ”¾é‡+æ¶¨åœå®¶æ•°å¼‚å¸¸')
    elif senti['score'] >= 30:
        senti['level'] = 'ğŸŸ¡'
    result['dimensions']['sentiment'] = senti

    # â•â•â•â•â•â•â• 4. å¤–éƒ¨å†²å‡» â•â•â•â•â•â•â•
    ext = {'name': 'ğŸŒ å¤–éƒ¨å†²å‡»', 'level': 'ğŸŸ¢', 'score': 0, 'items': [], 'trend': []}

    # ä¸­ç¾åˆ©å·®
    rates = load_json(RATES_JSON)
    spread_list = rates.get('spread', [])
    if spread_list:
        latest_spread = spread_list[-1]['spread']
        ext['items'].append(f"ä¸­ç¾åˆ©å·®: {latest_spread:+.2f}%")
        ext['trend'] = spread_list[-30:]  # æœ€è¿‘30å¤©

        if latest_spread < -2.0:
            ext['score'] += 40
            result['alerts'].append(f'ğŸŒ ä¸­ç¾åˆ©å·®{latest_spread:+.2f}%ï¼Œèµ„é‡‘å¤–æµå‹åŠ›å¤§')
        elif latest_spread < -1.5:
            ext['score'] += 20

        # å‘¨åº¦å˜åŒ–
        if len(spread_list) >= 6:
            week_ago = spread_list[-6]['spread']
            weekly_chg = latest_spread - week_ago
            if abs(weekly_chg) > 0.3:
                ext['items'].append(f"åˆ©å·®å‘¨å˜åŒ–: {weekly_chg:+.2f}%")
                ext['score'] += 15

    # æ±‡ç‡
    fx = rates.get('fx', {})
    cnh = fx.get('USDCNH.FX', {})
    if cnh.get('latest'):
        ext['items'].append(f"USDCNH: {cnh['latest']:.4f}")
        if cnh.get('change') and abs(cnh['change']) > 0.05:
            ext['score'] += 20
            result['alerts'].append(f"ğŸŒ USDCNHæ—¥æ³¢åŠ¨{cnh['change']:+.4f}ï¼Œæ±‡ç‡å¼‚åŠ¨")

    # Aè‚¡ç‰ˆVIXï¼šç”¨æœŸæƒIVåˆ†ä½ä»£æ›¿
    opt_data = load_json(OPTION_JSON)
    if opt_data:
        for underlying in opt_data.get('underlyings', []):
            if underlying.get('code') in ('000300', '510300'):
                summary = underlying.get('summary', {})
                iv_pct = summary.get('atm_iv_pct')
                if iv_pct is not None:
                    ext['items'].append(f"300æœŸæƒIVåˆ†ä½: {iv_pct:.0f}%")
                    if iv_pct > 80:
                        ext['score'] += 25
                        result['alerts'].append(f'ğŸŒ 300æœŸæƒIVåˆ†ä½{iv_pct:.0f}%ï¼Œéšå«æ³¢åŠ¨ç‡åé«˜')
                break

    ext['score'] = min(ext['score'], 100)
    scores['external'] = ext['score']
    if ext['score'] >= 60:
        ext['level'] = 'ğŸ”´'
    elif ext['score'] >= 30:
        ext['level'] = 'ğŸŸ¡'
    result['dimensions']['external'] = ext

    # â•â•â•â•â•â•â• 5. å¾®è§‚æ¶åŒ– â•â•â•â•â•â•â•
    micro = {'name': 'ğŸƒ å¾®è§‚æ¶åŒ–', 'level': 'ğŸŸ¢', 'score': 0, 'items': [], 'trend': []}

    # åŒ—å‘èµ„é‡‘
    nb_df = load_csv(os.path.join(BASE, 'micro_flow', 'crowding', 'cache'), 'northbound.csv')
    if not nb_df.empty:
        for col in nb_df.columns:
            if col != 'trade_date':
                nb_df[col] = pd.to_numeric(nb_df[col], errors='coerce')
        nb_df = nb_df.sort_values('trade_date')

        # æ‰¾å‡€ä¹°å…¥åˆ—
        buy_col = None
        for c in ['buy_amount', 'north_money', 'net_amount']:
            if c in nb_df.columns:
                buy_col = c
                break

        if buy_col:
            recent5 = nb_df[buy_col].tail(5)
            consecutive_out = int((recent5 < 0).sum())
            micro['items'].append(f"åŒ—å‘è¿‘5æ—¥å‡€æµå‡ºå¤©æ•°: {consecutive_out}")
            micro['trend'] = [{'date': str(int(r['trade_date']))[4:8],
                              'value': round(float(r[buy_col]) / 1e4, 2) if pd.notna(r[buy_col]) else None}
                             for _, r in nb_df.tail(30).iterrows()]

            if consecutive_out >= 5:
                micro['score'] += 40
                result['alerts'].append(f'ğŸƒ åŒ—å‘è¿ç»­{consecutive_out}æ—¥å‡€æµå‡º')
            elif consecutive_out >= 3:
                micro['score'] += 20

    # æœŸæƒPCR
    if opt_data:
        for underlying in opt_data.get('underlyings', []):
            if underlying.get('code') in ('000300', '510300'):
                summary = underlying.get('summary', {})
                pcr = summary.get('pcr_oi')
                if pcr is not None:
                    micro['items'].append(f"300æœŸæƒPCR(OI): {pcr:.2f}")
                    if pcr > 1.3:
                        micro['score'] += 30
                        result['alerts'].append(f'ğŸƒ 300æœŸæƒPCR {pcr:.2f}ï¼Œçœ‹ç©ºåŠ›é‡æé‡')
                    elif pcr > 1.0:
                        micro['score'] += 15
                break

    micro['score'] = min(micro['score'], 100)
    scores['micro'] = micro['score']
    if micro['score'] >= 60:
        micro['level'] = 'ğŸ”´'
    elif micro['score'] >= 30:
        micro['level'] = 'ğŸŸ¡'
    result['dimensions']['micro'] = micro

    # â•â•â•â•â•â•â• ç»¼åˆè¯„åˆ† â•â•â•â•â•â•â•
    weights = {'liquidity': 0.2, 'valuation': 0.25, 'sentiment': 0.2, 'external': 0.2, 'micro': 0.15}
    total = sum(scores.get(k, 0) * w for k, w in weights.items())
    result['composite_score'] = round(total, 1)

    if total >= 60:
        result['composite_level'] = 'é«˜é£é™© ğŸ”´'
    elif total >= 40:
        result['composite_level'] = 'ä¸­é«˜é£é™© ğŸŸ '
    elif total >= 20:
        result['composite_level'] = 'ä¸­ä½é£é™© ğŸŸ¡'
    else:
        result['composite_level'] = 'ä½é£é™© ğŸŸ¢'

    if not result['alerts']:
        result['alerts'] = ['å½“å‰æ— æç«¯é£é™©ä¿¡å· âœ…']

    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nè¾“å‡º: {OUTPUT_JSON}")
    print(f"ç»¼åˆé£é™©: {result['composite_score']:.1f}/100 - {result['composite_level']}")
    for a in result['alerts']:
        print(f"  âš ï¸ {a}")


if __name__ == '__main__':
    calc()
